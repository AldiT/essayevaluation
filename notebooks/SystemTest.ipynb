{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Full System Test\n",
    "This notebook is for testing the evaluation. \n",
    "\n",
    "Following is just some setup code which can be ignored."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import spacy\n",
    "from essay_evaluation.lexical_density import LexicalDensityFeatures\n",
    "from essay_evaluation.lexical_sophistication import LexicalSophisticationFeatures\n",
    "from essay_evaluation.lexical_variation import LexicalVariationFeatures\n",
    "from essay_evaluation.lexical_accuracy import LexicalAccuracy, SpellChecker, CollocationPreprocessor, \\\n",
    "    CollocationDectector, CollocationEvaluator\n",
    "from essay_evaluation.collocational_aspects import CollocationalAspects\n",
    "from essay_evaluation.formative_feedback_evaluator import binning_indicies, FormativeFeedbackEvaluator\n",
    "from essay_evaluation.pipeline import FeatureCollector\n",
    "from pprint import pprint\n",
    "\n",
    "all_feature_names = LexicalVariationFeatures.feature_names + LexicalSophisticationFeatures.feature_names + \\\n",
    "                LexicalAccuracy.feature_names + CollocationalAspects.feature_names + LexicalDensityFeatures.feature_names\n",
    "feature_names = [all_feature_names[index] for index in binning_indicies]\n",
    "\n",
    "def create_pipeline():\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "    # add all required components\n",
    "    spell_checker = SpellChecker()\n",
    "    nlp.add_pipe(spell_checker, name=spell_checker.name, last=True)\n",
    "\n",
    "    col_preproc = CollocationPreprocessor()\n",
    "    nlp.add_pipe(col_preproc, name=col_preproc.name, last=True)\n",
    "\n",
    "    col_detect = CollocationDectector()\n",
    "    nlp.add_pipe(col_detect, name=col_detect.name, last=True)\n",
    "\n",
    "    col_evaluator = CollocationEvaluator()\n",
    "    nlp.add_pipe(col_evaluator, name=col_evaluator.name, last=True)\n",
    "\n",
    "    # Add all feature extractors:\n",
    "    lvf = LexicalVariationFeatures()\n",
    "    lsf = LexicalSophisticationFeatures()\n",
    "    ldf = LexicalDensityFeatures()\n",
    "    la = LexicalAccuracy()\n",
    "    ca = CollocationalAspects()\n",
    "\n",
    "    nlp.add_pipe(lvf, name=lvf.name, last=True)\n",
    "    nlp.add_pipe(lsf, name=lsf.name, last=True)\n",
    "    nlp.add_pipe(la, name=la.name, last=True)\n",
    "    nlp.add_pipe(ca, name=ca.name, last=True)\n",
    "    nlp.add_pipe(ldf, name=ldf.name, last=True)\n",
    "\n",
    "    feature_collector = FeatureCollector()\n",
    "    nlp.add_pipe(feature_collector, name=feature_collector.name, last=True)\n",
    "    return nlp\n",
    "\n",
    "nlp = create_pipeline()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def get_feedback(text, level):\n",
    "    doc = nlp(text)\n",
    "    feature_matrix = np.array([doc._.features])\n",
    "    ffe = FormativeFeedbackEvaluator()\n",
    "    feedback = ffe(feature_matrix, level)\n",
    "    feedback = {feature: feedback for (feature, feedback) in zip(feature_names, feedback) }\n",
    "    return feedback, doc\n",
    "\n",
    "def analyze(doc):\n",
    "    print(\"Collocations\")\n",
    "    pprint([str(col) for col in doc._.collocations])\n",
    "    print(\"Collocations Errors\")\n",
    "    pprint([str(col) for col in doc._.collocation_errors])\n",
    "    print(\"Spelling Mistakes\")\n",
    "    pprint(doc._.spell_errors)\n",
    "    print(\"Feature Index Values\")\n",
    "    pprint({index: value for (index, value) in zip(all_feature_names, doc._.features)})\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Usage\n",
    "You can use the `feedback, doc = get_feedback(text,level)` method to retreive a dictionary containing the feature \n",
    "index and -1 for negative, 0 for neutral and 1 for positive feedback. This function also returns the \n",
    "spacy document. The `analyze(doc)` function prints out the collocation, collocation errors and \n",
    "spelling mistakes in order to debug the resulting feedback."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Collocations\n[]\nCollocations Errors\n[]\nSpelling Mistakes\n[]\nFeature Index Values\n{'CA_BIN1_R': 0,\n 'CA_BIN2_R': 0,\n 'CA_BIN3_R': 0,\n 'LA_COL_ERR_R': 0,\n 'LA_ER': 0.0,\n 'LD_GRUR': 0.3333333333333333,\n 'LD_LXUR': 0.0,\n 'LS_FOMN_BS': 0,\n 'LS_FOMN_CA': 298.0,\n 'LS_FOMN_NA': 0,\n 'LS_FOMN_NG': 0,\n 'LS_FOMN_TC': 0,\n 'LS_FPC_BS': 0.0,\n 'LS_FPC_CA': 0.0,\n 'LS_FPC_CGA1': 0.0,\n 'LS_FPC_CGA2': 0.0,\n 'LS_FPC_CGA3': 0.3333333333333333,\n 'LS_FPC_CT': 0.0,\n 'LS_FPC_NA': 0.0,\n 'LS_FPC_NG': 0.6666666666666666,\n 'LS_FPC_TC': 0.0,\n 'LV_CTTR': 0,\n 'LV_DUGA': 0,\n 'LV_HDD': 0.0,\n 'LV_MAAS': 0,\n 'LV_MATTR': 0,\n 'LV_MSTTR': 0,\n 'LV_MTLD': 0.0,\n 'LV_RTTR': 0,\n 'LV_SUMM': 0.0,\n 'LV_TTR': 0,\n 'LV_W': 0,\n 'LV_WT': 0,\n 'LV_WT1': 0,\n 'LV_YULEK': 0.0}\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "{'LV_HDD': -1,\n 'LS_FPC_CA': 0,\n 'LS_FPC_CT': -1,\n 'LS_FPC_CGA1': -1,\n 'LS_FPC_CGA2': 0,\n 'LS_FPC_CGA3': 1,\n 'LA_ER': 0,\n 'LA_COL_ERR_R': 1,\n 'CA_BIN1_R': 1,\n 'CA_BIN2_R': -1,\n 'CA_BIN3_R': -1,\n 'LD_LXUR': -1}"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 8
    }
   ],
   "source": [
    "feedback, doc = get_feedback(\"Hello World!\", \"a1\")\n",
    "analyze(doc)\n",
    "feedback"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Collocations\n['speech_NOUN<--[ NOUN+VERB (14.262473883594401) ]--be_VERB',\n 'commentator_NOUN<--[ NOUN+VERB (0.9998283007569059) ]--suggest_VERB',\n 'other_NOUN<--[ NOUN+VERB (None) ]--suggest_VERB',\n 'Wilberforces_NOUN<--[ NOUN+NOUN (None) ]--speech_NOUN',\n 'grandmother_NOUN<--[ NOUN+NOUN (None) ]--grandfather_NOUN',\n 'unfair_ADJ<--[ ADJ+NOUN (1.4265423231237808) ]--attack_NOUN',\n 'infamous_ADJ<--[ ADJ+NOUN (None) ]--question_NOUN',\n 'attack_NOUN<--[ VERB+NOUN (7.8036437881778316) ]--be_VERB',\n 'descent_NOUN<--[ VERB+NOUN (1.9255911974011508) ]--claim_VERB',\n 'question_NOUN<--[ VERB+NOUN (0.37029217508548135) ]--write_VERB',\n 'bishop_NOUN<--[ VERB+NOUN (None) ]--teach_VERB',\n 'humoured_ADJ<--[ VERB+ADJ (None) ]--be_VERB',\n 'good_ADV<--[ ADV+ADJ (None) ]--humoured_ADJ',\n 'now_ADV<--[ ADV+ADJ (None) ]--infamous_ADJ']\nCollocations Errors\n['other_NOUN<--[ NOUN+VERB (None) ]--suggest_VERB',\n 'Wilberforces_NOUN<--[ NOUN+NOUN (None) ]--speech_NOUN',\n 'grandmother_NOUN<--[ NOUN+NOUN (None) ]--grandfather_NOUN',\n 'infamous_ADJ<--[ ADJ+NOUN (None) ]--question_NOUN',\n 'bishop_NOUN<--[ VERB+NOUN (None) ]--teach_VERB',\n 'humoured_ADJ<--[ VERB+ADJ (None) ]--be_VERB',\n 'good_ADV<--[ ADV+ADJ (None) ]--humoured_ADJ',\n 'now_ADV<--[ ADV+ADJ (None) ]--infamous_ADJ']\nSpelling Mistakes\n[humoured]\nFeature Index Values\n{'CA_BIN1_R': 0.3333333333333333,\n 'CA_BIN2_R': 0.16666666666666666,\n 'CA_BIN3_R': 0.5,\n 'LA_COL_ERR_R': 0.5714285714285714,\n 'LA_ER': 0.014084507042253521,\n 'LD_GRUR': 0.1267605633802817,\n 'LD_LXUR': 0.323943661971831,\n 'LS_FOMN_BS': 722.5,\n 'LS_FOMN_CA': 0,\n 'LS_FOMN_NA': 2794.0,\n 'LS_FOMN_NG': 0,\n 'LS_FOMN_TC': 983527.1923076923,\n 'LS_FPC_BS': 0.028169014084507043,\n 'LS_FPC_CA': 0.0,\n 'LS_FPC_CGA1': 0.36619718309859156,\n 'LS_FPC_CGA2': 0.028169014084507043,\n 'LS_FPC_CGA3': 0.0,\n 'LS_FPC_CT': 0.028169014084507043,\n 'LS_FPC_NA': 0.014084507042253521,\n 'LS_FPC_NG': 0.43661971830985913,\n 'LS_FPC_TC': 0.0,\n 'LV_CTTR': 3.0962810792528397,\n 'LV_DUGA': 108.07004295213692,\n 'LV_HDD': 0.0,\n 'LV_MAAS': 0.009253258097092544,\n 'LV_MATTR': 23,\n 'LV_MSTTR': 23,\n 'LV_MTLD': 74.05999999999996,\n 'LV_RTTR': 4.37880269519857,\n 'LV_SUMM': 0.9742360060751417,\n 'LV_TTR': 0.9130434782608695,\n 'LV_W': 23,\n 'LV_WT': 21,\n 'LV_WT1': 19,\n 'LV_YULEK': 0.007561436672967864}\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "{'LV_HDD': -1,\n 'LS_FPC_CA': 0,\n 'LS_FPC_CT': 0,\n 'LS_FPC_CGA1': 1,\n 'LS_FPC_CGA2': 1,\n 'LS_FPC_CGA3': 0,\n 'LA_ER': 0,\n 'LA_COL_ERR_R': 0,\n 'CA_BIN1_R': -1,\n 'CA_BIN2_R': 0,\n 'CA_BIN3_R': -1,\n 'LD_LXUR': -1}"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 9
    }
   ],
   "source": [
    "text2 = \"Wilberforce's speech on 30 June 1860 was good-humoured and witty, but was an unfair attack on Darwinism, ending in the now infamous question to Huxley of whether \\\"it was through his grandfather or grandmother that he claimed descent from a monkey.\\\" Some commentators suggested that this question was written by Owen, and others suggested that the bishop was taught by Owen.\"\n",
    "feedback, doc = get_feedback(text2, \"a1\")\n",
    "analyze(doc)\n",
    "feedback\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}